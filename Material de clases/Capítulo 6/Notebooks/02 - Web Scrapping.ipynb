{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhlQiAcuyZJg"
   },
   "source": [
    "<p>\n",
    "<font size='5' face='Georgia, Arial'>IIC2115 - Programación como herramienta para la ingeniería</font><br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OgO72zcEyZJj"
   },
   "source": [
    "# Web Scrapping\n",
    "\n",
    "En este capítulo haremos una introducción a ***Web Scrapping***. Este es el proceso de extraer información de sitios web. El scraping de datos se enfoca en transformar el contenido no estructurado de un sitio web (usualmente HTML) en datos estructurados los que pueden ser almacenados en una base datos, en una hoja de cálculo o en el mismo código.\n",
    "\n",
    "La forma en que los datos son extraídos de un sitio web es similar a la utilizada por los bots de búsqueda - la navegación web humana es simulada utilizando programas (bots) los que extraen (scrape) los datos de un sitio web.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iirPjIRxyZJm"
   },
   "source": [
    "## Tipos de páginas Web\n",
    "\n",
    "A la hora de hacer scrapping en páginas web, es importante distinguir cómo está construida y alojada la información. Esta puede estar contenida directamente en el html (estática) o puede ser generada por alguna incrustación dinámica dentro del html como un javaScript (dinámica).\n",
    "\n",
    "La información estática es de más facil acceso ya se encuentra contenida directamente en el html y es en la que profundizaremos. \n",
    "\n",
    "Si necesita trabajar con páginas web deinámicas es recomendable investigar la librería `Selenium` de Python. Esta permite simular un usuario que interactúa en una página web donde se permite la recolección de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fZ7J7cAE0mA"
   },
   "source": [
    "## Aplicación con Beatiful Soup\n",
    "\n",
    "Para el caso de realizar Web Scrapping en páginas que són estáticas se recomienda el uso de la librería `Beatiful Soup`. Con esta librería desarrollaremos el siguiente ejemplo. Suponga que se requiere desarrollar una aplicación que permita conocer el valor de la UTM en todo momento. Para conocer dicho valor podemos basarnos en el que publica la web \"prensa digital\" [aqui](https://www.prensadigital.cl/valor-utm-unidad-tributaria-mensual.html).\n",
    "\n",
    "### PASO 1: Conocer y familiarizarse con la web\n",
    "\n",
    "Es fuertemente recomendable que utilicen el navegador Google Chrome para abrir la url. Una vez abierta, debe seleccionar el valor del dolar y con click secundario selecciones \"inspeccionar elemento\". Ahora podrán ver el código de la pagina web y familiarizarse con ella.\n",
    "\n",
    "### PASO 2: Descargar el html\n",
    "\n",
    "Ahora utilizaremos la librería urllib para simular un navegador y descargar el código fuente de la página:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2726,
     "status": "ok",
     "timestamp": 1541056702168,
     "user": {
      "displayName": "Francisco Garrido Valenzuela",
      "photoUrl": "",
      "userId": "05801830879928469527"
     },
     "user_tz": 180
    },
    "id": "bicENIvg864V",
    "outputId": "3f919867-02f7-442d-aa3b-6a99ef962f9c"
   },
   "outputs": [],
   "source": [
    "import urllib.request as net\n",
    "import ssl\n",
    "\n",
    "class WebDownloader:\n",
    "    \n",
    "    def __init__(self, link):\n",
    "        self.user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "        self.url =  link\n",
    "        \n",
    "        \n",
    "    def getHtmlAsString(self):\n",
    "        headers = {'User-Agent':self.user_agent}\n",
    "        request= net.Request(self.url,None,headers)\n",
    "        gcontext = ssl.SSLContext()\n",
    "        response = net.urlopen(request,context=gcontext)\n",
    "        return response.read().decode('utf-8')\n",
    "    \n",
    "wd = WebDownloader('https://www.prensadigital.cl/valor-utm-unidad-tributaria-mensual.html')\n",
    "sourceCode = wd.getHtmlAsString()\n",
    "print(sourceCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5UQRwn5CF2s"
   },
   "source": [
    "### PASO 3: Buscar el valor solicitado\n",
    "\n",
    "Al revisar el código fuente, es posible notar que el valor de la UTM se encuentra dentro del archivo que acabamos de descargar. En este caso basta con \"jugar\" con el string descargado para poder obtener el valor buscado.\n",
    "\n",
    "Pero existe una forma un poco más directa. Si luego de la inspección de elemento en Google Chrome, seleccionamos el valor buscado y vemos el nodo en el que está contenido. En este caso lo vemos en:\n",
    "\n",
    "`<td>48.016</td>`\n",
    "\n",
    "esta dentro del nodo \"td\", en este caso podemos acceder a todos los nodos con ese nombre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDghNLnyAz1f"
   },
   "outputs": [],
   "source": [
    "# si la librería bs4 no está instalada, el siguiente ejemplo generará un error.\n",
    "# para instalarla, ejecute el siguiente comando en una celda: !pip install bs4\n",
    "import bs4\n",
    "\n",
    "info = []\n",
    "\n",
    "soup = bs4.BeautifulSoup(sourceCode)\n",
    "\n",
    "for node in soup.findAll('td'):\n",
    "    info.append(str(u''.join(node.findAll(text=True)).encode('utf-8'))[2:-1])\n",
    "    \n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ht--g2-cKMtL"
   },
   "source": [
    "En este caso vemos como apuntaba a la tabla de la web.\n",
    "\n",
    "### PASO 4: Mostrar la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1541057157537,
     "user": {
      "displayName": "Francisco Garrido Valenzuela",
      "photoUrl": "",
      "userId": "05801830879928469527"
     },
     "user_tz": 180
    },
    "id": "DR65XjR9H0EG",
    "outputId": "f0086e0e-0904-456b-c840-8adef95a4cab"
   },
   "outputs": [],
   "source": [
    "print(\"El valor actual de la UTM es: {}\".format(info[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQBrqKEtKk1_"
   },
   "source": [
    "Funciona!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_lq20UdKp2l"
   },
   "source": [
    "En general Web Scrapping es a medida. Es decir, deben desarrollarse distintas herramientas en función de las necesidades. Documentarse correctamente es fundamental. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "03 - Introducción a Web Scrapping.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "interpreter": {
   "hash": "5f0c199c1b13c591dc8d2398e4aa6037b22139c5b858b148853eacad2edb87e5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
